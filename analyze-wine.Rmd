---
title: "Classification Analyze Quality Wine with Naive Bayes, Decision Tree, and Random Forest"
author: "Gasha Sarwono"
output: 
  html_document:
    theme: flatly
    higlight: zenburn
    toc: true
    toc_float:
      collapsed: true
    df_print: paged
---

![](D:\Gasha\wine.jpg)

## Background

**This is data characteristic about wine quality, like chemical content and quality standard.**

**My purpose use this data is to analysis quality of wine based on chemical content.**

**Description Data:**

-fixed acidity: most acids involved with wine

-volatile acidity: amount of acetic acid in wine

-citric acid: found in small quantities

-residual sugar: amount of sugar remaining after wine fermentation/production

-chlorides: amount of salt in the wine

-free sulfur dioxide: free forms of S02, prevents microbial growth and the oxidation of wine

-total sulfur dioxide: amount of free and bound forms of S02

-density: the density of water depending on the percent alcohol and sugar content

-pH: describes how acidic or basic a wine is on a scale 0-14 (very acidic: 0, very basic: 14); most wines are between 3-4 on the pH scale

-sulphates: an antimicrobial and antioxidant

-alcohol: the percent alcohol content of the wine

**The data I get from Kaggle with this following link:**

https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009

## Set Up

**Activated Library**

```{r message=FALSE, warning=FALSE}

library(dplyr) #wrangling data
library(tidyverse) #make plot
library(caret) #confussion matrix
library(rsample) #sampling data
library(e1071) #naive bayes
library(partykit) #decisioin tree
library(randomForest) #random forest
library(ROCR) #check ROC

options(scipen = 999)
```

**Import Data**

```{r}
wine <- read.csv("winequality-red.csv")
wine
```

## Exploratory Data Analysis 

**Check Data Type**

```{r}
glimpse(wine)
```

All variable appropriate with data type

**Classification target variable**

Make standard score of quality, quality >= 7 is "Good" and quality < 7 is "Bad". Put classification score quality in new column

```{r}
wine$class <- as.factor(ifelse(wine$quality >= 7 , "Good" , "Bad"))
wine
```

**Check missing value**

```{r}
colSums(is.na(wine))
```

Data no have missing value

## Modelling

**Cross Validation**

Unselect variable quality because I want machine can learning with label target variable

```{r}
wine <- 
  wine %>% 
  select(-quality)
```

Make data train for training model (80% proportion from actual data) and data test for testing model (20% proportion from actual data)

```{r warning=FALSE}
RNGkind(sample.kind = "Rounding")
set.seed(1616)

index <- sample(nrow(wine), 
                nrow(wine)*0.8)

wine.train <- wine[index, ]
wine.test <- wine[-index, ]
```

**Check proportion data train**

Check proportion because training model can optimal if the data balance

```{r}
prop.table(table(wine.train$class))

```

Data train imbalance, so we need to make balance with downsampling methode

```{r}
wine_train_down <- downSample(x = wine.train %>%  select(-class),
                              y = wine.train$class,
                              yname = "class")

prop.table(table(wine_train_down$class))

```

Data train already balance and ready to train model.

### Naive Bayes

**Make Naive Bayes Model**

```{r}
model_naive <- naiveBayes(x = wine_train_down %>% select(-class), 
                          y = wine_train_down$class, 
                          laplace = 1) 
```

**Make Prediction and Evaluation Model**

```{r}
pred_naive <- predict(object= model_naive,
                           newdata = wine.test,
                           type="class")

confusionMatrix(data= pred_naive,
                reference= wine.test$class,
                positive="Good")
```

**Check Performance Model**

1. Receiver-Operating Curve (ROC)

ROC is a curve are plots correlation between True Positive Rate (Sensitivity or Recall) and False Positive Rate (Specificity). Good model ideally "High TP and Low FP"

```{r}
wine_predProb <- predict(model_naive, newdata = wine.test,type = "raw")
head(wine_predProb)
```

Check ROC with plot

```{r}
#create prediction object
wine_roc <- prediction(predictions = wine_predProb[, 2],
                       labels = as.numeric(wine.test$class == "Good"))

#create performance with prediction object
perf <- performance(prediction.obj = wine_roc,
                    measure = "tpr", # tpr = true positive rate
                    x.measure = "fpr") #fpr = false positive rate
                    
#create lot
plot(perf)
abline(0,1, lty = 2)
```

Based on plot, line make a curve arc (High True Positive and Low False Positive) its mean good model

2. Area Under ROC Curve (AUC)

AUC show large are under ROC curve, parameter AUC if value close to 1, model good.

```{r}
auc <- performance(prediction.obj = wine_roc, 
                   measure = "auc")
auc@y.values
```

Value AUC 0.864411, close to 1 its means good model

**Interpretation Naive Bayes Model**

-Accuracy : 0.7312 –> 73.1% model to correctly guess the target (Good / Bad).

-Sensitivity (Recall) : 0.8837 –> 88.3% from all the positive actual data, capable proportion of model to guess right.

-Specificity : 0.7076 –> 70.7% from all the negative actual data, capable proportion of model to guess right.

-Pos Pred (Precision) : 0.3193 –> 31.9% from all the prediction result, capable model to correctly guess the positive class.

Based on Confussion Matrix model Naive Bayes, value Accuracy (0.7312 or 73.1%) and (Recall 0.8837 or 88.3% model). Its means Accuracy model can predict quality wine Good or Bad 73.1% and model can predict quality wine Good is 88.3%.

### Decision Tree

**Make Decision Tree Model**

```{r}
set.seed(1616)
model_dt <- ctree(class ~ ., wine)

```

**Make Prediction and Evaluation Model**

Prediction and Evaluation Model using *data test*

```{r}
pred_dt <- predict(model_dt, newdata = wine.test, type = "response")

confusionMatrix(pred_dt, wine.test$class, positive = "Good")
```

Prediction and Evaluation Model using *data train*

```{r}
pred_dt_train <- predict(model_dt, newdata = wine_train_down, type = "response")
confusionMatrix(pred_dt_train, wine_train_down$class, positive = "Good")
```

**Summary Prediction and Evaluation**

```{r}
model_dt_recap <- c("wine.test", "wine_train_down")
Accuracy <- c(0.8969,0.7184)
Recall <- c(0.46512,0.5000)

tabelmodelrecap <- data.frame(model_dt_recap,Accuracy,Recall)

print(tabelmodelrecap)
```

Cause value Accuracy with data_test and data_train imbalance (overfitting), model must to prunning to make right fitting.

**Pruning Model**

Create new model with pruning treatment

```{r}
set.seed(1616)

model_dt_tuned <- ctree(class ~ ., wine_train_down,
                               control = ctree_control(mincriterion = 0.5,
                                            minsplit = 35, #40
                                            minbucket = 20)) #12
```

**Make Prediction and Evaluation Model**

Prediction and Evaluation Model using *data test*

```{r}
pred_dt_test_tunes <- predict(model_dt_tuned, newdata = wine.test, type = "response")
confusionMatrix(pred_dt_test_tunes, wine.test$class, positive = "Good")
```

Prediction and Evaluation Model using *data train*

```{r}
pred_dt_train_tunes <- predict(model_dt_tuned, newdata = wine_train_down, type = "response")
confusionMatrix(pred_dt_train_tunes, wine_train_down$class, positive = "Good")
```

**Summary Prediction and Evaluation**

```{r}
model_dt_recap_prun <- c("wine.test", "wine_train_down")
Accuracy_prun <- c(0.7875,0.8046)
Recall_prun <- c(0.7674,0.7931)

tabelmodelrecap2 <- data.frame(model_dt_recap_prun,Accuracy_prun,Recall_prun)

print(tabelmodelrecap2)
```

After prunning, result Accuracy and Recall already imbalance (right fitting)

**Create Plot Decision Tree**

```{r}
model_dt_tuned
```

```{r fig.width = 15}
plot(model_dt_tuned,type="simple")
```

**Interpretation Decision Tree Model**

- Nodes 1 is Root Nodes (Highest node in the tree structure, and has no parent)

- Nodes 2,3,4,9,10,and 11 is Inner Nodes (Node of a tree that has child nodes)

- Nodes 5,6,7,8,12,13,14,and 15 is Terminal Nodes (Node that does not have child nodes)

### Random Forest

**K-Fold Cross Validation** 

Split data by $k$ part, where each part is used to testing data.

Make model random forest using 5-fold cross validation and repeat process 3 times, after that save on RDS

```{r}
set.seed(1616)

ctrl <- trainControl(method = "repeatedcv",
                      number = 5,
                      repeats = 3) 
 
model_forest <- train(class ~ .,
                  data = wine_train_down,
                  method = "rf", 
                  trControl = ctrl)
 
saveRDS(model_forest, "model_forest_update.RDS")
```

**Make Random Forest Model**

Read RDS with name model_rf

```{r}
model_rf <- readRDS("model_forest_update.RDS")
model_rf
```

Use model with mtry (predictor) = 2, because value accuracy more than other mtry 

**Model Evaluation**

Check model error (OOB or Out-Off-Bag) with finalModel

```{r}
model_rf$finalModel
```

Result (OOB or Out-Off-Bag) is 16.95% , its mean this model has 83.05% of accuracy

**Check Importance Variabel**

```{r warning=F, error=FALSE}
varImp(model_rf)
```

```{r}
plot(varImp(model_rf))
```

Based on plot above, 3 most important variable is alcohol, sulphates and volatile.acidity

**Make Prediction and Evaluation Model**

Make prediction and check model evaluation with positive class "Good" using data_test

```{r}
pred_rf <- predict(model_rf, wine.test, type = "raw")
confusionMatrix(pred_rf, wine.test$class, positive = "Good")
```

**Interpretation Random Forest Model**

-Accuracy : 0.7781 –> 77.8% model to correctly guess the target (Good / Bad).

-Sensitivity (Recall) : 0.9070 –> 90.7% from all the positive actual data, capable proportion of model to guess right.

-Specificity : 0.7581  –> 75.8% from all the negative actual data, capable proportion of model to guess right.

-Pos Pred (Precision) : 0.3679 –> 36.7% from all the prediction result, capable model to correctly guess the positive class.

Based on Confussion Matrix model Random Forest, value Accuracy (0.7812 or 78.1%) and (Recall 0.9070 or 90.07% model). Its means Accuracy model can predict quality wine Good or Bad 78.1% and model can predict quality wine Good is 90.07%.

## Conclusion

```{r}
Model_Name <- c("Naive Bayes", "Decission Tree", "Random Forest")
Accuracy <- c(0.7312,0.7875,0.7781)
Recall <- c(0.8837,0.7674,0.9070)
Specificity <- c(0.7076,0.7906,0.7581)
Precision <- c(0.3193,0.3626,0.3679)

modelrecapall <- data.frame(Model_Name,Accuracy,Recall,Specificity,Precision)

print(modelrecapall)
```

After make 3 model we get result Accuracy, Recall, Specificity, and Precision. In this case we will choose Random Forest Model, because model can predict quality wine "Good" and "Bad" with accuracy 77.8% and model can predict quality "Good" 90.7%. So we want all wine quality Bad not mix with all wine quality Good.






